{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import serial\n",
    "from threading import Thread\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "import cv2\n",
    "import os.path\n",
    "import numpy as np\n",
    "from utils.eval import *\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the Serial\n",
    "ser = serial.Serial('COM3', 9600)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_serial(serial_msg):\n",
    "    \"\"\"\n",
    "    Function to parse serial data to extract float values\n",
    "    format 'x:19.34 y:23.01 z:-33.83' to x, y, z float values\n",
    "\n",
    "    Args:\n",
    "        - (str) string with format 'x:19.34 y:23.01 z:-33.83'\n",
    "    Return:\n",
    "        - (list) x, y, z float values\n",
    "    \"\"\"\n",
    "    xyz_list = re.findall('[-+]?[0-9]*\\.?[0-9]*', serial_msg)\n",
    "    return [float(i) for i in filter(lambda item: item, xyz_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateOrientation(ser):\n",
    "    \"\"\"\n",
    "    Function to integration the x data from the Gyroscope\n",
    "    and update the global variable x_orientation with the new value\n",
    "\n",
    "    Args:\n",
    "        - (serial.Serial) serial to get the gyroscope data\n",
    "    \"\"\"\n",
    "    global x_orientation\n",
    "\n",
    "    while True:\n",
    "        serial_msg_bytes = ser.readline()\n",
    "        serial_msg = serial_msg_bytes.decode()\n",
    "        dx, dy, dz = parse_serial(serial_msg)\n",
    "        \n",
    "        # The gyroscope values are in degrees-per-second\n",
    "        # divide each value by the number of samples per second\n",
    "        dx_normalized = dx / gyroscope_sample_rate;\n",
    "\n",
    "        # remove noise\n",
    "        if(abs(dx_normalized) > 0.004):\n",
    "            # update orientation\n",
    "            x_orientation = x_orientation - dx_normalized*1.25\n",
    "            x_orientation = x_orientation%360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update orientation in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize x orientation\n",
    "x_orientation = 0\n",
    "\n",
    "# 119 got from Arduino with IMU.gyroscopeSampleRate();\n",
    "gyroscope_sample_rate = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the thread to update the x orientation in real time\n",
    "Thread(target=UpdateOrientation, args=(ser,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot orientation in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    plt.clf()\n",
    "\n",
    "    # plot origin in blue\n",
    "    plt.scatter(0, 0, s=100, c='b')\n",
    "\n",
    "    # find position of the end of the needle\n",
    "    # 0.1 far from origin in direction of the orientation\n",
    "    distance = 0.1\n",
    "    x_orientation_rad = math.radians(x_orientation)\n",
    "    x_pos = math.cos(x_orientation_rad)*distance\n",
    "    y_pos = math.sin(x_orientation_rad)*distance\n",
    "\n",
    "    # plot line between both position with circles\n",
    "    plt.plot([0, x_pos], [0, y_pos], 'ro-')\n",
    "    \n",
    "    plt.xlim([-distance, distance])\n",
    "    plt.ylim([-distance, distance])\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot orientation in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "while True:\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # plot origin in blue\n",
    "    ax.scatter(0, 0, s=100, c='b')\n",
    "\n",
    "    # find position of the end of the needle\n",
    "    # 0.1 far from origin in direction of the orientation\n",
    "    distance = 0.1\n",
    "    x_orientation_rad = math.radians(x_orientation)\n",
    "    x_pos = math.cos(x_orientation_rad)*distance\n",
    "    y_pos = math.sin(x_orientation_rad)*distance\n",
    "\n",
    "    # plot line between both position with circles\n",
    "    ax.quiver(0, 0, 0, x_pos, y_pos, 0,\n",
    "              length=distance, normalize=True)\n",
    "\n",
    "    ax.set_xlim(-distance, distance)\n",
    "    ax.set_ylim(-distance, distance)\n",
    "    ax.set_zlim(-distance, distance)\n",
    "   \n",
    "    plt.show()\n",
    "    plt.pause(0.1)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get depth image and do projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_FILE_PATH = 'model/midas_v2_1_small.tflite'\n",
    "\n",
    "if not os.path.isfile(TFLITE_FILE_PATH):\n",
    "    tflite_model_url = \"https://tfhub.dev/intel/lite-model/midas/v2_1_small/1/lite/1?lite-format=tflite\"\n",
    "    urllib.request.urlretrieve(tflite_model_url, TFLITE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_FILE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16ae956bdc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input image\n",
    "img = cv2.imread('images/dog.jpg')\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess input image\n",
    "input_data = preprocess_image(rgb_img, [256, 256])\n",
    "\n",
    "# reshape data according to input_details\n",
    "input_data = tf.transpose(input_data, [0, 2, 3, 1])\n",
    "\n",
    "# Get result\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = tf.squeeze(interpreter.get_tensor(output_details[0]['index']), axis=0)\n",
    "\n",
    "depth_map = output_data.numpy()\n",
    "plt.imshow(depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=180.79759>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=883.7121>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(output_data), tf.reduce_max(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth_value = tf.reduce_min(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix(orientation):\n",
    "    rotation_matrix = np.array([[1, 0, 0],\n",
    "                                [0, math.cos(orientation), -math.sin(orientation)],\n",
    "                                [0, math.sin(orientation), math.cos(orientation)]])\n",
    "    return rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vector = np.array([0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1       , 0.13660254, 0.03660254])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(unit_vector, get_rotation_matrix(math.radians(30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1641.04it/s]\n"
     ]
    }
   ],
   "source": [
    "image_width = 1280\n",
    "image_height = 720\n",
    "\n",
    "x_depth_rescale_factor = depth_map.shape[0] / image_width\n",
    "y_depth_rescale_factor = depth_map.shape[1] / image_height\n",
    "\n",
    "h_fov = math.radians(60)\n",
    "v_fov = math.radians(35)\n",
    "\n",
    "x_focal = image_width / (2*math.tan(h_fov/2))\n",
    "y_focal = image_height / (2*math.tan(v_fov/2))\n",
    "\n",
    "c_x = (0.5*image_width)\n",
    "c_y = (0.5*image_height)\n",
    "\n",
    "points_in_ned = []\n",
    "depth_values = []\n",
    "\n",
    "for x in tqdm(range(image_width)):\n",
    "    for y in range(image_height):\n",
    "\n",
    "        # keep 0.1% of the points\n",
    "        if random.randint(0, 999) >= 1:\n",
    "            continue\n",
    "\n",
    "        # get depth value\n",
    "        x_depth_pos = int(x*x_depth_rescale_factor)\n",
    "        y_depth_pos = int(y*y_depth_rescale_factor)\n",
    "        depth_value = depth_map[x_depth_pos, y_depth_pos, 0]\n",
    "\n",
    "        # get 3d vector\n",
    "        x_point = depth_value * (x - c_x) / x_focal\n",
    "        y_point = depth_value * (y - c_y) / y_focal\n",
    "        point_3d_before_rotation = np.array([x_point, y_point, depth_value])\n",
    "\n",
    "        # projection in function of the orientation\n",
    "        point_3d_after_rotation = np.matmul(get_rotation_matrix(math.radians(x_orientation)), point_3d_before_rotation)\n",
    "        points_in_ned.append(point_3d_after_rotation)\n",
    "        depth_values.append(depth_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_in_ned = np.array(points_in_ned)\n",
    "len(points_in_ned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "rainbow = cm.get_cmap('rainbow', 12)\n",
    "depth_values_normalized = depth_values/max(depth_values)\n",
    "colormap = rainbow(depth_values_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# plot origin in blue\n",
    "ax.scatter(0, 0, s=100, c='b')\n",
    "\n",
    "# plot x, y, z referential\n",
    "ax.quiver(0, 0, 0, 1, 0, 0,\n",
    "          length=min_depth_value/2, normalize=True, color='r')\n",
    "ax.text(min_depth_value/2, 0, 0, \"x\", color='r')\n",
    "ax.quiver(0, 0, 0, 0, 1, 0,\n",
    "          length=min_depth_value/2, normalize=True, color='g')\n",
    "ax.text(0, min_depth_value/2, 0, \"y\", color='g')\n",
    "ax.quiver(0, 0, 0, 0, 0, 1,\n",
    "          length=min_depth_value/2, normalize=True, color='b')\n",
    "ax.text(0, 0, min_depth_value/2, \"z\", color='b')\n",
    "\n",
    "# find position of the end of the needle\n",
    "x_orientation_rad = math.radians(x_orientation)\n",
    "x_pos = 0\n",
    "y_pos = -math.sin(x_orientation_rad)\n",
    "z_pos = math.cos(x_orientation_rad)\n",
    "\n",
    "# plot arrow for robot orientation\n",
    "ax.quiver(0, 0, 0, -z_pos, y_pos, x_pos,\n",
    "          length=min_depth_value/2, normalize=True, color='black')\n",
    "\n",
    "# plot projected points in 3D\n",
    "ax.scatter(-points_in_ned[:, 2], points_in_ned[:, 1], points_in_ned[:, 0], c=colormap)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul projection in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_FILE_PATH = 'model/midas_v2_1_small.tflite'\n",
    "\n",
    "if not os.path.isfile(TFLITE_FILE_PATH):\n",
    "    tflite_model_url = \"https://tfhub.dev/intel/lite-model/midas/v2_1_small/1/lite/1?lite-format=tflite\"\n",
    "    urllib.request.urlretrieve(tflite_model_url, TFLITE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_FILE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_width, depth_height = output_details[0]['shape'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-353823461d64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m720\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_depth_rescale_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_depth_rescale_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'depth_map' is not defined"
     ]
    }
   ],
   "source": [
    "image_width = 1280\n",
    "image_height = 720\n",
    "\n",
    "x_depth_rescale_factor = depth_map.shape[0] / image_width\n",
    "y_depth_rescale_factor = depth_map.shape[1] / image_height\n",
    "\n",
    "h_fov = math.radians(60)\n",
    "v_fov = math.radians(35)\n",
    "\n",
    "x_focal = image_width / (2*math.tan(h_fov/2))\n",
    "y_focal = image_height / (2*math.tan(v_fov/2))\n",
    "\n",
    "c_x = (0.5*image_width)\n",
    "c_y = (0.5*image_height)\n",
    "\n",
    "rainbow = cm.get_cmap('rainbow', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depthmap(rgb_img):\n",
    "    # preprocess input image\n",
    "    input_data = preprocess_image(rgb_img, [256, 256])\n",
    "\n",
    "    # reshape data according to input_details\n",
    "    input_data = tf.transpose(input_data, [0, 2, 3, 1])\n",
    "\n",
    "    # Get result\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = tf.squeeze(interpreter.get_tensor(output_details[0]['index']), axis=0)\n",
    "\n",
    "    depth_map = output_data.numpy()\n",
    "\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_points_from_depthmap(depth_map, pourcentage_to_keep=1):\n",
    "    points_in_ned = []\n",
    "    depth_values = []\n",
    "\n",
    "    for x in tqdm(range(image_width)):\n",
    "        for y in range(image_height):\n",
    "\n",
    "            # keep 0.1% of the points\n",
    "            if random.randint(0, 999) >= pourcentage_to_keep:\n",
    "                continue\n",
    "\n",
    "            # get depth value\n",
    "            x_depth_pos = int(x*x_depth_rescale_factor)\n",
    "            y_depth_pos = int(y*y_depth_rescale_factor)\n",
    "            depth_value = depth_map[x_depth_pos, y_depth_pos, 0]\n",
    "\n",
    "            # get 3d vector\n",
    "            x_point = depth_value * (x - c_x) / x_focal\n",
    "            y_point = depth_value * (y - c_y) / y_focal\n",
    "            point_3d_before_rotation = np.array([x_point, y_point, depth_value])\n",
    "\n",
    "            # projection in function of the orientation\n",
    "            point_3d_after_rotation = np.matmul(get_rotation_matrix(math.radians(x_orientation)), point_3d_before_rotation)\n",
    "            points_in_ned.append(point_3d_after_rotation)\n",
    "            depth_values.append(depth_value)\n",
    "    return np.array(points_in_ned), depth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1666.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1608.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1720.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1662.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1738.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1713.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1720.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1748.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1734.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1647.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1694.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1675.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1710.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1646.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1737.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1673.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1761.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1742.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1725.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1747.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1759.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1710.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1723.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1684.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1692.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1772.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1713.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:00<00:00, 1783.33it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████████▍    | 1204/1280 [00:00<00:00, 1653.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-250-0a4a770b28da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# get projection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdepth_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_depthmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mpoints_in_ned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_3d_points_from_depthmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mmax_depth_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdepth_values_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth_values\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmax_depth_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-238-43b60e55222d>\u001b[0m in \u001b[0;36mget_3d_points_from_depthmap\u001b[1;34m(depth_map, pourcentage_to_keep)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;31m# keep 0.1% of the points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mpourcentage_to_keep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\random.py\u001b[0m in \u001b[0;36mrandint\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \"\"\"\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_randbelow_with_getrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\random.py\u001b[0m in \u001b[0;36mrandrange\u001b[1;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mistop\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"non-integer stop for randrange()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mistop\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mistart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get input image\n",
    "img = cv2.imread('images/dog.jpg')\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "while True:\n",
    "    x_orientation += 15\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # get projection\n",
    "    depth_map = get_depthmap(rgb_img)\n",
    "    points_in_ned, depth_values = get_3d_points_from_depthmap(depth_map)\n",
    "    max_depth_value = max(depth_values)\n",
    "    depth_values_normalized = depth_values/max_depth_value\n",
    "    min_depth_value = min(depth_values)\n",
    "    colormap = rainbow(depth_values_normalized)\n",
    "\n",
    "    # plot origin in blue\n",
    "    ax.scatter(0, 0, s=100, c='b')\n",
    "\n",
    "    # plot x, y, z referential\n",
    "    ax.quiver(0, 0, 0, 1, 0, 0,\n",
    "              length=min_depth_value/2, normalize=True, color='r')\n",
    "    ax.text(min_depth_value/2, 0, 0, \"x\", color='r')\n",
    "    ax.quiver(0, 0, 0, 0, 1, 0,\n",
    "              length=min_depth_value/2, normalize=True, color='g')\n",
    "    ax.text(0, min_depth_value/2, 0, \"y\", color='g')\n",
    "    ax.quiver(0, 0, 0, 0, 0, 1,\n",
    "              length=min_depth_value/2, normalize=True, color='b')\n",
    "    ax.text(0, 0, min_depth_value/2, \"z\", color='b')\n",
    "\n",
    "    # find position of the end of the needle\n",
    "    x_orientation_rad = math.radians(x_orientation)\n",
    "    x_pos = 0\n",
    "    y_pos = -math.sin(x_orientation_rad)\n",
    "    z_pos = math.cos(x_orientation_rad)\n",
    "\n",
    "    # plot arrow for robot orientation\n",
    "    ax.quiver(0, 0, 0, -z_pos, y_pos, x_pos,\n",
    "              length=min_depth_value/2, normalize=True, color='black')\n",
    "\n",
    "    # plot projected points in 3D\n",
    "    ax.scatter(-points_in_ned[:, 2], points_in_ned[:, 1], points_in_ned[:, 0], c=colormap)\n",
    "\n",
    "    ax.view_init(elev=30, azim=10)\n",
    "    ax.set_xlim(-max_depth_value, max_depth_value)\n",
    "    ax.set_ylim(-max_depth_value, max_depth_value)\n",
    "    ax.set_zlim(-max_depth_value, max_depth_value)\n",
    "    plt.show()\n",
    "    plt.pause(0.5)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
